#!/usr/bin/env python3
"""
é˜¶æ®µ4æµ‹è¯•éªŒè¯è„šæœ¬: é”™è¯¯å¤„ç†ä¸å¥å£®æ€§
æµ‹è¯•èµ„æºç®¡ç†ã€é”™è¯¯å¤„ç†ã€å¤§æ–‡ä»¶å¤„ç†ç­‰åŠŸèƒ½
"""

import json
import logging
import os
import tempfile
import time
from pathlib import Path
from typing import Dict, Any

from utils.resource_manager import (
    ResourceManager, MemoryThresholds, DiskThresholds,
    ResourceMonitor, MemoryManager, LargeFileHandler
)
from utils.errors import ErrorCollector, FileError, DecodeError
from core.processor import EnhancedBatchProcessor
from core.scanner import DirectoryScanner

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æ–°å¢å¯¼å…¥
from Pkt2TXT.utils.helpers import get_file_size_mb

class Stage4Validator:
    """é˜¶æ®µ4åŠŸèƒ½éªŒè¯å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–éªŒè¯å™¨"""
        self.test_results = {}
        self.temp_dir = Path(tempfile.mkdtemp(prefix="pcap_decoder_stage4_"))
        logger.info(f"åˆå§‹åŒ–é˜¶æ®µ4éªŒè¯å™¨ï¼Œä¸´æ—¶ç›®å½•: {self.temp_dir}")
    
    def test_resource_monitor(self) -> Dict[str, Any]:
        """æµ‹è¯•èµ„æºç›‘æ§å™¨"""
        logger.info("=== æµ‹è¯•èµ„æºç›‘æ§å™¨ ===")
        
        results = {
            'test_name': 'èµ„æºç›‘æ§å™¨æµ‹è¯•',
            'start_time': time.time(),
            'tests': []
        }
        
        # æµ‹è¯•1: åŸºæœ¬ç›‘æ§åŠŸèƒ½
        try:
            monitor = ResourceMonitor(monitoring_interval=1.0)
            
            # è·å–å½“å‰ä½¿ç”¨æƒ…å†µ
            usage = monitor.get_current_usage()
            
            test_result = {
                'name': 'åŸºæœ¬ç›‘æ§åŠŸèƒ½',
                'success': True,
                'details': {
                    'memory_mb': round(usage.memory_mb, 2),
                    'memory_percent': round(usage.memory_percent, 2),
                    'disk_free_gb': round(usage.disk_free_gb, 2),
                    'timestamp': usage.timestamp
                }
            }
            
            # éªŒè¯æ•°æ®åˆç†æ€§
            if usage.memory_mb <= 0 or usage.disk_free_gb <= 0:
                test_result['success'] = False
                test_result['error'] = "èµ„æºä½¿ç”¨æ•°æ®å¼‚å¸¸"
            
            results['tests'].append(test_result)
            logger.info(f"âœ… åŸºæœ¬ç›‘æ§åŠŸèƒ½: å†…å­˜ {usage.memory_mb:.1f}MB, ç£ç›˜å‰©ä½™ {usage.disk_free_gb:.1f}GB")
            
        except Exception as e:
            results['tests'].append({
                'name': 'åŸºæœ¬ç›‘æ§åŠŸèƒ½',
                'success': False,
                'error': str(e)
            })
            logger.error(f"âŒ åŸºæœ¬ç›‘æ§åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•2: é˜ˆå€¼æ£€æŸ¥
        try:
            thresholds = MemoryThresholds(warning_mb=100.0, critical_mb=200.0)
            disk_thresholds = DiskThresholds(min_free_gb=0.1, warning_free_gb=1.0)
            
            monitor = ResourceMonitor(
                memory_thresholds=thresholds,
                disk_thresholds=disk_thresholds
            )
            
            usage = monitor.get_current_usage()
            
            # æ¨¡æ‹Ÿè§¦å‘é˜ˆå€¼æ£€æŸ¥
            warnings_triggered = []
            criticals_triggered = []
            
            def warning_callback(message, usage):
                warnings_triggered.append(message)
            
            def critical_callback(message, usage):
                criticals_triggered.append(message)
            
            monitor.add_warning_callback(warning_callback)
            monitor.add_critical_callback(critical_callback)
            
            monitor.check_thresholds(usage)
            
            test_result = {
                'name': 'é˜ˆå€¼æ£€æŸ¥',
                'success': True,
                'details': {
                    'warnings_triggered': len(warnings_triggered),
                    'criticals_triggered': len(criticals_triggered),
                    'current_memory_mb': usage.memory_mb,
                    'warning_threshold': thresholds.warning_mb,
                    'critical_threshold': thresholds.critical_mb
                }
            }
            
            results['tests'].append(test_result)
            logger.info(f"âœ… é˜ˆå€¼æ£€æŸ¥: {len(warnings_triggered)} è­¦å‘Š, {len(criticals_triggered)} ä¸´ç•Œ")
            
        except Exception as e:
            results['tests'].append({
                'name': 'é˜ˆå€¼æ£€æŸ¥',
                'success': False,
                'error': str(e)
            })
            logger.error(f"âŒ é˜ˆå€¼æ£€æŸ¥æµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•3: çŸ­æœŸç›‘æ§è¿è¡Œ
        try:
            monitor = ResourceMonitor(monitoring_interval=0.5)
            monitor.start_monitoring()
            
            # è¿è¡Œ2ç§’
            time.sleep(2)
            
            monitor.stop_monitoring()
            
            summary = monitor.get_usage_summary()
            
            test_result = {
                'name': 'çŸ­æœŸç›‘æ§è¿è¡Œ',
                'success': summary['sample_count'] > 0,
                'details': {
                    'sample_count': summary['sample_count'],
                    'monitoring_duration': round(summary['monitoring_duration'], 2),
                    'peak_memory_mb': round(summary['peak_memory_mb'], 2),
                    'avg_memory_mb': round(summary['avg_memory_mb'], 2)
                }
            }
            
            if summary['sample_count'] == 0:
                test_result['error'] = "æ²¡æœ‰æ”¶é›†åˆ°ç›‘æ§æ ·æœ¬"
            
            results['tests'].append(test_result)
            logger.info(f"âœ… çŸ­æœŸç›‘æ§: {summary['sample_count']} ä¸ªæ ·æœ¬, æŒç»­ {summary['monitoring_duration']:.1f}s")
            
        except Exception as e:
            results['tests'].append({
                'name': 'çŸ­æœŸç›‘æ§è¿è¡Œ',
                'success': False,
                'error': str(e)
            })
            logger.error(f"âŒ çŸ­æœŸç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
        
        results['end_time'] = time.time()
        results['duration'] = results['end_time'] - results['start_time']
        results['success_count'] = sum(1 for test in results['tests'] if test['success'])
        results['total_count'] = len(results['tests'])
        
        return results
    
    def test_memory_manager(self) -> Dict[str, Any]:
        """æµ‹è¯•å†…å­˜ç®¡ç†å™¨"""
        logger.info("=== æµ‹è¯•å†…å­˜ç®¡ç†å™¨ ===")
        
        results = {
            'test_name': 'å†…å­˜ç®¡ç†å™¨æµ‹è¯•',
            'start_time': time.time(),
            'tests': []
        }
        
        # æµ‹è¯•1: åƒåœ¾å›æ”¶
        try:
            manager = MemoryManager()
            
            # è®°å½•åˆå§‹å†…å­˜
            initial_stats = manager.get_memory_stats()
            
            # æ‰§è¡Œåƒåœ¾å›æ”¶
            collected = manager.force_garbage_collection()
            
            # è®°å½•æ¸…ç†åå†…å­˜
            final_stats = manager.get_memory_stats()
            
            test_result = {
                'name': 'å¼ºåˆ¶åƒåœ¾å›æ”¶',
                'success': True,
                'details': {
                    'objects_collected': sum(collected.values()),
                    'gc_generations': collected,
                    'initial_memory_mb': round(initial_stats['rss_mb'], 2),
                    'final_memory_mb': round(final_stats['rss_mb'], 2),
                    'memory_change_mb': round(final_stats['rss_mb'] - initial_stats['rss_mb'], 2)
                }
            }
            
            results['tests'].append(test_result)
            logger.info(f"âœ… åƒåœ¾å›æ”¶: æ¸…ç† {sum(collected.values())} å¯¹è±¡")
            
        except Exception as e:
            results['tests'].append({
                'name': 'å¼ºåˆ¶åƒåœ¾å›æ”¶',
                'success': False,
                'error': str(e)
            })
            logger.error(f"âŒ åƒåœ¾å›æ”¶æµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•2: æ¸…ç†å›è°ƒ
        try:
            manager = MemoryManager()
            
            callback_called = []
            
            def test_callback():
                callback_called.append(time.time())
            
            manager.register_cleanup_callback(test_callback)
            
            # æ‰§è¡Œæ¸…ç†
            manager.force_garbage_collection()
            
            test_result = {
                'name': 'æ¸…ç†å›è°ƒæœºåˆ¶',
                'success': len(callback_called) > 0,
                'details': {
                    'callbacks_called': len(callback_called),
                    'registered_callbacks': manager.get_memory_stats()['cleanup_callbacks_count']
                }
            }
            
            if len(callback_called) == 0:
                test_result['error'] = "æ¸…ç†å›è°ƒæœªè¢«è°ƒç”¨"
            
            results['tests'].append(test_result)
            logger.info(f"âœ… æ¸…ç†å›è°ƒ: {len(callback_called)} æ¬¡è°ƒç”¨")
            
        except Exception as e:
            results['tests'].append({
                'name': 'æ¸…ç†å›è°ƒæœºåˆ¶',
                'success': False,
                'error': str(e)
            })
            logger.error(f"âŒ æ¸…ç†å›è°ƒæµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•3: æ¡ä»¶æ¸…ç†
        try:
            manager = MemoryManager()
            
            # æµ‹è¯•ä½é˜ˆå€¼ï¼ˆåº”è¯¥ä¸æ¸…ç†ï¼‰
            cleaned_low = manager.cleanup_if_needed(threshold_mb=10000.0)
            
            # æµ‹è¯•é«˜é˜ˆå€¼ï¼ˆåº”è¯¥æ¸…ç†ï¼‰
            cleaned_high = manager.cleanup_if_needed(threshold_mb=1.0)
            
            test_result = {
                'name': 'æ¡ä»¶å†…å­˜æ¸…ç†',
                'success': True,
                'details': {
                    'low_threshold_cleaned': cleaned_low,
                    'high_threshold_cleaned': cleaned_high,
                    'current_memory_mb': round(manager.get_memory_stats()['rss_mb'], 2)
                }
            }
            
            results['tests'].append(test_result)
            logger.info(f"âœ… æ¡ä»¶æ¸…ç†: ä½é˜ˆå€¼ {cleaned_low}, é«˜é˜ˆå€¼ {cleaned_high}")
            
        except Exception as e:
            results['tests'].append({
                'name': 'æ¡ä»¶å†…å­˜æ¸…ç†',
                'success': False,
                'error': str(e)
            })
            logger.error(f"âŒ æ¡ä»¶æ¸…ç†æµ‹è¯•å¤±è´¥: {e}")
        
        results['end_time'] = time.time()
        results['duration'] = results['end_time'] - results['start_time']
        results['success_count'] = sum(1 for test in results['tests'] if test['success'])
        results['total_count'] = len(results['tests'])
        
        return results
    
    def test_large_file_handler(self) -> Dict[str, Any]:
        """æµ‹è¯•å¤§æ–‡ä»¶å¤„ç†å™¨"""
        logger.info("=== æµ‹è¯•å¤§æ–‡ä»¶å¤„ç†å™¨ ===")
        
        results = {
            'test_name': 'å¤§æ–‡ä»¶å¤„ç†å™¨æµ‹è¯•',
            'start_time': time.time(),
            'tests': []
        }
        
        # æµ‹è¯•1: æ–‡ä»¶å¤§å°æ£€æŸ¥
        try:
            handler = LargeFileHandler(max_file_size_mb=10.0)
            
            # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
            small_file = self.temp_dir / "small_test.txt"
            large_file = self.temp_dir / "large_test.txt"
            
            # å°æ–‡ä»¶
            with open(small_file, 'w') as f:
                f.write("small file content")
            
            # å¤§æ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿï¼‰
            with open(large_file, 'w') as f:
                f.write("x" * (15 * 1024 * 1024))  # 15MB
            
            small_is_large = handler.is_large_file(str(small_file))
            large_is_large = handler.is_large_file(str(large_file))
            
            small_size = get_file_size_mb(str(small_file))
            large_size = get_file_size_mb(str(large_file))
            
            test_result = {
                'name': 'æ–‡ä»¶å¤§å°æ£€æŸ¥',
                'success': not small_is_large and large_is_large,
                'details': {
                    'small_file_size_mb': round(small_size, 3),
                    'large_file_size_mb': round(large_size, 1),
                    'small_is_large': small_is_large,
                    'large_is_large': large_is_large,
                    'threshold_mb': 10.0
                }
            }
            
            if small_is_large or not large_is_large:
                test_result['error'] = "æ–‡ä»¶å¤§å°åˆ¤æ–­é”™è¯¯"
            
            results['tests'].append(test_result)
            logger.info(f"âœ… æ–‡ä»¶å¤§å°æ£€æŸ¥: å°æ–‡ä»¶ {small_size:.3f}MB, å¤§æ–‡ä»¶ {large_size:.1f}MB")
            
        except Exception as e:
            results['tests'].append({
                'name': 'æ–‡ä»¶å¤§å°æ£€æŸ¥',
                'success': False,
                'error': str(e)
            })
            logger.error(f"âŒ æ–‡ä»¶å¤§å°æ£€æŸ¥å¤±è´¥: {e}")
        
        # æµ‹è¯•2: ä¸´æ—¶æ–‡ä»¶ç®¡ç†
        try:
            handler = LargeFileHandler(temp_dir=str(self.temp_dir))
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_file1 = handler.create_temp_file(".test1")
            temp_file2 = handler.create_temp_file(".test2")
            
            # å†™å…¥å†…å®¹
            with open(temp_file1, 'w') as f:
                f.write("temp file 1")
            with open(temp_file2, 'w') as f:
                f.write("temp file 2")
            
            files_before_cleanup = len(handler.temp_files)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            handler.cleanup_temp_files()
            
            files_after_cleanup = len(handler.temp_files)
            file1_exists = temp_file1.exists()
            file2_exists = temp_file2.exists()
            
            test_result = {
                'name': 'ä¸´æ—¶æ–‡ä»¶ç®¡ç†',
                'success': files_before_cleanup == 2 and files_after_cleanup == 0 and not file1_exists and not file2_exists,
                'details': {
                    'files_before_cleanup': files_before_cleanup,
                    'files_after_cleanup': files_after_cleanup,
                    'temp_file1_exists': file1_exists,
                    'temp_file2_exists': file2_exists
                }
            }
            
            if files_before_cleanup != 2 or files_after_cleanup != 0:
                test_result['error'] = "ä¸´æ—¶æ–‡ä»¶ç®¡ç†å¼‚å¸¸"
            
            results['tests'].append(test_result)
            logger.info(f"âœ… ä¸´æ—¶æ–‡ä»¶ç®¡ç†: {files_before_cleanup} -> {files_after_cleanup} æ–‡ä»¶")
            
        except Exception as e:
            results['tests'].append({
                'name': 'ä¸´æ—¶æ–‡ä»¶ç®¡ç†',
                'success': False,
                'error': str(e)
            })
            logger.error(f"âŒ ä¸´æ—¶æ–‡ä»¶ç®¡ç†æµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•3: å†…å­˜ä¼°ç®—
        try:
            handler = LargeFileHandler()
            
            if large_file.exists():
                estimated_memory = handler.estimate_processing_memory(str(large_file))
                actual_size = get_file_size_mb(str(large_file))
                
                # ä¼°ç®—åº”è¯¥æ˜¯æ–‡ä»¶å¤§å°çš„2-3å€
                expected_min = actual_size * 2
                expected_max = actual_size * 3
                
                test_result = {
                    'name': 'å†…å­˜éœ€æ±‚ä¼°ç®—',
                    'success': expected_min <= estimated_memory <= expected_max,
                    'details': {
                        'file_size_mb': round(actual_size, 1),
                        'estimated_memory_mb': round(estimated_memory, 1),
                        'ratio': round(estimated_memory / actual_size, 1),
                        'expected_range': f"{expected_min:.1f}-{expected_max:.1f}"
                    }
                }
                
                if not (expected_min <= estimated_memory <= expected_max):
                    test_result['error'] = "å†…å­˜ä¼°ç®—è¶…å‡ºé¢„æœŸèŒƒå›´"
            else:
                test_result = {
                    'name': 'å†…å­˜éœ€æ±‚ä¼°ç®—',
                    'success': False,
                    'error': "æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨"
                }
            
            results['tests'].append(test_result)
            if test_result['success']:
                logger.info(f"âœ… å†…å­˜ä¼°ç®—: {test_result['details']['file_size_mb']}MB æ–‡ä»¶éœ€è¦ {test_result['details']['estimated_memory_mb']}MB å†…å­˜")
            
        except Exception as e:
            results['tests'].append({
                'name': 'å†…å­˜éœ€æ±‚ä¼°ç®—',
                'success': False,
                'error': str(e)
            })
            logger.error(f"âŒ å†…å­˜ä¼°ç®—æµ‹è¯•å¤±è´¥: {e}")
        
        results['end_time'] = time.time()
        results['duration'] = results['end_time'] - results['start_time']
        results['success_count'] = sum(1 for test in results['tests'] if test['success'])
        results['total_count'] = len(results['tests'])
        
        return results
    
    def test_error_handling(self) -> Dict[str, Any]:
        """æµ‹è¯•é”™è¯¯å¤„ç†æœºåˆ¶"""
        logger.info("=== æµ‹è¯•é”™è¯¯å¤„ç†æœºåˆ¶ ===")
        
        results = {
            'test_name': 'é”™è¯¯å¤„ç†æœºåˆ¶æµ‹è¯•',
            'start_time': time.time(),
            'tests': []
        }
        
        # æµ‹è¯•1: é”™è¯¯æ”¶é›†å™¨
        try:
            collector = ErrorCollector()
            
            # æ·»åŠ å„ç§é”™è¯¯
            file_error = FileError("test.pcap", "è¯»å–", IOError("æ–‡ä»¶ä¸å­˜åœ¨"))
            decode_error = DecodeError("test.pcap", packet_number=5, protocol="TCP")
            
            collector.add_error(file_error, "test.pcap")
            collector.add_error(decode_error, "test.pcap")
            collector.add_warning("è¿™æ˜¯ä¸€ä¸ªè­¦å‘Š", "test.pcap", {"detail": "test"})
            
            summary = collector.get_error_summary()
            report = collector.generate_error_report()
            
            test_result = {
                'name': 'é”™è¯¯æ”¶é›†å™¨',
                'success': True,
                'details': {
                    'total_errors': summary['total_errors'],
                    'total_warnings': summary['total_warnings'],
                    'files_with_errors': summary['files_with_errors'],
                    'error_types': summary['error_types'],
                    'has_errors': collector.has_errors(),
                    'has_warnings': collector.has_warnings()
                }
            }
            
            # éªŒè¯é”™è¯¯æ”¶é›†
            expected_errors = 2
            expected_warnings = 1
            
            if summary['total_errors'] != expected_errors or summary['total_warnings'] != expected_warnings:
                test_result['success'] = False
                test_result['error'] = f"é”™è¯¯æ•°é‡ä¸åŒ¹é…: æœŸæœ› {expected_errors} é”™è¯¯ {expected_warnings} è­¦å‘Š"
            
            results['tests'].append(test_result)
            logger.info(f"âœ… é”™è¯¯æ”¶é›†: {summary['total_errors']} é”™è¯¯, {summary['total_warnings']} è­¦å‘Š")
            
        except Exception as e:
            results['tests'].append({
                'name': 'é”™è¯¯æ”¶é›†å™¨',
                'success': False,
                'error': str(e)
            })
            logger.error(f"âŒ é”™è¯¯æ”¶é›†æµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•2: æŸåæ–‡ä»¶å¤„ç†
        try:
            # åˆ›å»ºæ— æ•ˆçš„pcapæ–‡ä»¶
            invalid_pcap = self.temp_dir / "invalid.pcap"
            with open(invalid_pcap, 'w') as f:
                f.write("è¿™ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„PCAPæ–‡ä»¶")
            
            # å°è¯•ç”¨æ‰¹é‡å¤„ç†å™¨å¤„ç†
            output_dir = self.temp_dir / "error_test_output"
            
            with EnhancedBatchProcessor(
                output_dir=str(output_dir),
                max_workers=1,
                task_timeout=10,
                enable_resource_monitoring=False
            ) as processor:
                
                # åˆ›å»ºåŒ…å«æ— æ•ˆæ–‡ä»¶çš„è¾“å…¥ç›®å½•
                input_dir = self.temp_dir / "error_test_input"
                input_dir.mkdir(exist_ok=True)
                
                # å¤åˆ¶æ— æ•ˆæ–‡ä»¶åˆ°è¾“å…¥ç›®å½•
                import shutil
                shutil.copy2(invalid_pcap, input_dir / "invalid.pcap")
                
                # å¤„ç†æ–‡ä»¶
                summary = processor.process_files(str(input_dir))
            
            test_result = {
                'name': 'æŸåæ–‡ä»¶å¤„ç†',
                'success': True,
                'details': {
                    'total_files': summary['processing_summary']['total_files'],
                    'failed_files': summary['processing_summary']['failed_files'],
                    'success_rate': summary['processing_summary']['success_rate'],
                    'error_count': summary['error_summary']['total_errors']
                }
            }
            
            # åº”è¯¥å¤„ç†å¤±è´¥ä½†ç¨‹åºä¸å´©æºƒ
            if summary['processing_summary']['failed_files'] == 0:
                test_result['success'] = False
                test_result['error'] = "æŸåæ–‡ä»¶åº”è¯¥å¤„ç†å¤±è´¥"
            
            results['tests'].append(test_result)
            logger.info(f"âœ… æŸåæ–‡ä»¶å¤„ç†: {summary['processing_summary']['failed_files']} ä¸ªæ–‡ä»¶å¤±è´¥")
            
        except Exception as e:
            results['tests'].append({
                'name': 'æŸåæ–‡ä»¶å¤„ç†',
                'success': False,
                'error': str(e)
            })
            logger.error(f"âŒ æŸåæ–‡ä»¶å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        
        results['end_time'] = time.time()
        results['duration'] = results['end_time'] - results['start_time']
        results['success_count'] = sum(1 for test in results['tests'] if test['success'])
        results['total_count'] = len(results['tests'])
        
        return results
    
    def test_integrated_resource_management(self) -> Dict[str, Any]:
        """æµ‹è¯•é›†æˆèµ„æºç®¡ç†"""
        logger.info("=== æµ‹è¯•é›†æˆèµ„æºç®¡ç† ===")
        
        results = {
            'test_name': 'é›†æˆèµ„æºç®¡ç†æµ‹è¯•',
            'start_time': time.time(),
            'tests': []
        }
        
        # æµ‹è¯•1: èµ„æºç®¡ç†å™¨ç»¼åˆåŠŸèƒ½
        try:
            # è‡ªå®šä¹‰é˜ˆå€¼
            memory_thresholds = MemoryThresholds(warning_mb=500.0, critical_mb=1000.0)
            disk_thresholds = DiskThresholds(min_free_gb=0.5, warning_free_gb=2.0)
            
            with ResourceManager(
                memory_thresholds=memory_thresholds,
                disk_thresholds=disk_thresholds,
                enable_monitoring=True
            ) as rm:
                
                # ç­‰å¾…ç›‘æ§å¯åŠ¨
                time.sleep(1)
                
                # æ£€æŸ¥çŠ¶æ€
                status = rm.get_comprehensive_status()
                
                # åˆ›å»ºä¸€ä¸ªæµ‹è¯•æ–‡ä»¶
                test_file = self.temp_dir / "resource_test.txt"
                with open(test_file, 'w') as f:
                    f.write("x" * 1024)  # 1KBæ–‡ä»¶
                
                # æ£€æŸ¥æ–‡ä»¶å¯å¤„ç†æ€§
                processability = rm.check_file_processable(str(test_file))
                
                test_result = {
                    'name': 'èµ„æºç®¡ç†å™¨ç»¼åˆåŠŸèƒ½',
                    'success': True,
                    'details': {
                        'monitoring_active': status['monitor_summary']['sample_count'] > 0,
                        'current_memory_mb': round(status['monitor_summary']['current'].memory_mb, 2),
                        'temp_files_count': status['temp_files_count'],
                        'file_processable': processability['can_process'],
                        'file_size_mb': processability['file_size_mb']
                    }
                }
                
                if not processability['can_process']:
                    test_result['success'] = False
                    test_result['error'] = "å°æ–‡ä»¶åº”è¯¥å¯ä»¥å¤„ç†"
                
                results['tests'].append(test_result)
                logger.info(f"âœ… èµ„æºç®¡ç†å™¨: å†…å­˜ {test_result['details']['current_memory_mb']}MB, ç›‘æ§æ ·æœ¬ {status['monitor_summary']['sample_count']}")
                
        except Exception as e:
            results['tests'].append({
                'name': 'èµ„æºç®¡ç†å™¨ç»¼åˆåŠŸèƒ½',
                'success': False,
                'error': str(e)
            })
            logger.error(f"âŒ èµ„æºç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•2: å¢å¼ºæ‰¹é‡å¤„ç†å™¨
        try:
            # å¯»æ‰¾çœŸå®çš„æµ‹è¯•æ•°æ®
            test_data_dirs = [
                "tests/data/samples",
                "../tests/data/samples",
                "../../tests/data/samples"
            ]
            
            test_dir = None
            for data_dir in test_data_dirs:
                if Path(data_dir).exists():
                    test_dir = data_dir
                    break
            
            if test_dir:
                output_dir = self.temp_dir / "enhanced_processor_test"
                
                with EnhancedBatchProcessor(
                    output_dir=str(output_dir),
                    max_workers=2,
                    task_timeout=30,
                    memory_limit_mb=1000.0,
                    enable_resource_monitoring=True
                ) as processor:
                    
                    # å¤„ç†å°‘é‡æ–‡ä»¶
                    summary = processor.process_files(test_dir)
                
                test_result = {
                    'name': 'å¢å¼ºæ‰¹é‡å¤„ç†å™¨',
                    'success': True,
                    'details': {
                        'total_files': summary['processing_summary']['total_files'],
                        'successful_files': summary['processing_summary']['successful_files'],
                        'failed_files': summary['processing_summary']['failed_files'],
                        'skipped_files': summary['processing_summary']['skipped_files'],
                        'peak_memory_mb': summary['resource_metrics']['peak_memory_mb'],
                        'processing_time': summary['processing_summary']['total_processing_time']
                    }
                }
                
                if summary['processing_summary']['total_files'] == 0:
                    test_result['success'] = False
                    test_result['error'] = "æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ–‡ä»¶"
                
                results['tests'].append(test_result)
                logger.info(f"âœ… å¢å¼ºå¤„ç†å™¨: {summary['processing_summary']['successful_files']}/{summary['processing_summary']['total_files']} æ–‡ä»¶æˆåŠŸ")
                
            else:
                results['tests'].append({
                    'name': 'å¢å¼ºæ‰¹é‡å¤„ç†å™¨',
                    'success': False,
                    'error': "æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®ç›®å½•"
                })
                logger.warning("âš ï¸ è·³è¿‡å¢å¼ºå¤„ç†å™¨æµ‹è¯•: æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®")
            
        except Exception as e:
            results['tests'].append({
                'name': 'å¢å¼ºæ‰¹é‡å¤„ç†å™¨',
                'success': False,
                'error': str(e)
            })
            logger.error(f"âŒ å¢å¼ºå¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        
        results['end_time'] = time.time()
        results['duration'] = results['end_time'] - results['start_time']
        results['success_count'] = sum(1 for test in results['tests'] if test['success'])
        results['total_count'] = len(results['tests'])
        
        return results
    
    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰é˜¶æ®µ4æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹é˜¶æ®µ4åŠŸèƒ½éªŒè¯")
        
        overall_start = time.time()
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        test_results = {
            'resource_monitor': self.test_resource_monitor(),
            'memory_manager': self.test_memory_manager(),
            'large_file_handler': self.test_large_file_handler(),
            'error_handling': self.test_error_handling(),
            'integrated_resource_management': self.test_integrated_resource_management()
        }
        
        overall_end = time.time()
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_tests = sum(result['total_count'] for result in test_results.values())
        total_success = sum(result['success_count'] for result in test_results.values())
        overall_success_rate = (total_success / total_tests * 100) if total_tests > 0 else 0
        
        summary = {
            'stage': 4,
            'stage_name': 'é”™è¯¯å¤„ç†ä¸å¥å£®æ€§',
            'start_time': overall_start,
            'end_time': overall_end,
            'duration': overall_end - overall_start,
            'total_tests': total_tests,
            'successful_tests': total_success,
            'failed_tests': total_tests - total_success,
            'success_rate': round(overall_success_rate, 1),
            'test_categories': len(test_results),
            'detailed_results': test_results
        }
        
        return summary
    
    def save_report(self, results: Dict[str, Any], filename: str = "stage4_validation_report.json"):
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Š"""
        report_file = self.temp_dir / filename
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        return str(report_file)
    
    def cleanup(self):
        """æ¸…ç†æµ‹è¯•èµ„æº"""
        try:
            import shutil
            if self.temp_dir.exists():
                shutil.rmtree(self.temp_dir)
            logger.info("æµ‹è¯•èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.warning(f"æ¸…ç†æµ‹è¯•èµ„æºæ—¶å‡ºé”™: {e}")


def main():
    """ä¸»å‡½æ•°"""
    validator = Stage4Validator()
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        results = validator.run_all_tests()
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = validator.save_report(results)
        
        # æ˜¾ç¤ºæ±‡æ€»ç»“æœ
        print("\n" + "="*60)
        print("ğŸ¯ é˜¶æ®µ4éªŒè¯ç»“æœæ±‡æ€»")
        print("="*60)
        print(f"æµ‹è¯•é˜¶æ®µ: {results['stage_name']}")
        print(f"æ€»æµ‹è¯•æ•°: {results['total_tests']}")
        print(f"æˆåŠŸæµ‹è¯•: {results['successful_tests']}")
        print(f"å¤±è´¥æµ‹è¯•: {results['failed_tests']}")
        print(f"æˆåŠŸç‡: {results['success_rate']}%")
        print(f"æ€»è€—æ—¶: {results['duration']:.2f}ç§’")
        print(f"æµ‹è¯•ç±»åˆ«: {results['test_categories']}")
        print(f"è¯¦ç»†æŠ¥å‘Š: {report_file}")
        
        # æ˜¾ç¤ºå„ç±»åˆ«ç»“æœ
        print("\nğŸ“Š å„ç±»åˆ«æµ‹è¯•ç»“æœ:")
        for category, result in results['detailed_results'].items():
            status = "âœ…" if result['success_count'] == result['total_count'] else "âŒ"
            print(f"{status} {result['test_name']}: {result['success_count']}/{result['total_count']} é€šè¿‡")
        
        # åˆ¤æ–­æ•´ä½“ç»“æœ
        if results['success_rate'] >= 80:
            print(f"\nğŸ‰ é˜¶æ®µ4éªŒè¯æˆåŠŸ! (æˆåŠŸç‡: {results['success_rate']}%)")
            return 0
        else:
            print(f"\nâš ï¸ é˜¶æ®µ4éªŒè¯éœ€è¦æ”¹è¿› (æˆåŠŸç‡: {results['success_rate']}%)")
            return 1
            
    except Exception as e:
        logger.error(f"éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        return 1
        
    finally:
        validator.cleanup()


if __name__ == "__main__":
    exit(main()) 